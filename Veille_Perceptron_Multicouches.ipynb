{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4ace76-9e7e-4445-b6e3-76f2f59f224d",
   "metadata": {},
   "source": [
    "# Veille sur le Perceptron Multicouches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ba09d-553a-4dcb-9308-2544baae7341",
   "metadata": {},
   "source": [
    "### 1. Réalisez une veille sur le Perceptron Multicouches et expliquez son architecture\n",
    "(couches d’entrée, couches cachées, couches de sortie, couches denses, etc).\n",
    "Quels sont ses hyperparamètres ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffc272-9833-4799-ad35-1b491d73a2a5",
   "metadata": {},
   "source": [
    "Le Perceptron Multicouches (PMC), également connu sous le nom de réseau de neurones multicouches, est un type de modèle d'apprentissage profond utilisé dans le domaine de l'apprentissage automatique. Il est composé de plusieurs couches de neurones artificiels organisées de manière hiérarchique.\n",
    "\n",
    "L'architecture du Perceptron Multicouches se compose généralement de trois types de couches principales : les couches d'entrée, les couches cachées et les couches de sortie.\n",
    "\n",
    "    1. Couches d'entrée : \n",
    "        Les couches d'entrée sont responsables de recevoir les données d'entrée et de les transmettre aux couches suivantes. Chaque neurone dans cette couche représente une caractéristique distincte des données d'entrée. Par exemple, si vous travaillez avec des images en niveaux de gris de taille 28x28, chaque neurone de la couche d'entrée représentera un pixel de l'image.\n",
    "\n",
    "    2. Couches cachées :\n",
    "        Les couches cachées sont situées entre les couches d'entrée et les couches de sortie. Elles sont appelées \"cachées\" car elles ne sont pas directement exposées aux données d'entrée ou de sortie. Chaque couche cachée est composée de plusieurs neurones, et chaque neurone est connecté à tous les neurones de la couche précédente et de la couche suivante.\n",
    "\n",
    "    3. Couches de sortie :\n",
    "        Les couches de sortie sont responsables de produire les résultats finaux   du modèle. La structure et le nombre de neurones dans cette couche dépendent de la tâche spécifique. Par exemple, pour un problème de classification binaire, il y aurait un seul neurone de sortie qui donne une valeur entre 0 et 1, représentant la probabilité d'appartenance à une classe.\n",
    "\n",
    "    En plus de ces couches principales, il peut y avoir des couches denses (ou entièrement connectées) qui sont utilisées pour augmenter la flexibilité du modèle. Dans une couche dense, chaque neurone est connecté à tous les neurones de la couche précédente.\n",
    "\n",
    "Les hyperparamètres du Perceptron Multicouches sont des paramètres réglables qui déterminent l'architecture et le comportement du modèle. Les principaux hyperparamètres sont :\n",
    "\n",
    "        1. Nombre de couches cachées : Cela détermine combien de couches cachées seront présentes dans le réseau.\n",
    "\n",
    "        2. Nombre de neurones par couche cachée : Cela détermine le nombre de neurones dans chaque couche cachée. Un nombre plus élevé de neurones permet généralement d'apprendre des caractéristiques plus complexes, mais cela augmente également la complexité du modèle.\n",
    "\n",
    "        3. Fonction d'activation : C'est la fonction mathématique appliquée à chaque neurone pour introduire une non-linéarité dans le modèle. Des exemples de fonctions d'activation couramment utilisées sont la fonction sigmoïde, la fonction ReLU (Rectified Linear Unit) et la fonction tanh (tangente hyperbolique).\n",
    "\n",
    "        4. Taux d'apprentissage : Il s'agit du facteur qui détermine la taille des pas de mise à jour des poids lors de l'apprentissage du modèle. Un taux d'apprentissage élevé peut entraîner une convergence rapide mais risque de passer à côté du minimum global, tandis qu'un taux d'apprentissage faible peut prendre plus de temps pour converger.\n",
    "\n",
    "        5. Nombre d'itérations (epochs) : Cela détermine le nombre de fois que le modèle parcourt l'ensemble des données d'entraînement lors de l'apprentissage.\n",
    "\n",
    "Ces hyperparamètres sont généralement définis par l'utilisateur et peuvent être ajustés pour trouver le meilleur compromis entre l'ajustement du modèle et la généralisation aux nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3341502-9c20-476c-94f8-11b69a45bd33",
   "metadata": {},
   "source": [
    "### 2. Expliquez le choix de l’architecture du PMC en fonction de la problématique de classification ou de régression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa55382-14c2-446b-aba3-190462d82f53",
   "metadata": {},
   "source": [
    "Le choix de l'architecture du Perceptron Multicouches (PMC) dépend de la nature de la problématique, qu'il s'agisse d'une tâche de classification ou de régression.\n",
    "\n",
    "       Pour une problématique de classification, où l'objectif est de prédire une classe ou une étiquette discrète, l'architecture typique du PMC comprend une couche de sortie avec un nombre de neurones correspondant au nombre de classes possibles. Chaque neurone de la couche de sortie est généralement activé par une fonction d'activation softmax, qui produit des probabilités pour chaque classe. La classe prédite sera celle ayant la plus grande probabilité. En ce qui concerne les couches cachées, il n'y a pas de règle stricte pour déterminer le nombre optimal de couches ou de neurones. Cependant, il est généralement recommandé de commencer avec une architecture simple et d'augmenter progressivement la complexité si nécessaire. Des études empiriques et des techniques de validation croisée peuvent être utilisées pour trouver l'architecture optimale.\n",
    "\n",
    "    Pour une problématique de régression, où l'objectif est de prédire une valeur numérique continue, l'architecture du PMC diffère légèrement. La couche de sortie ne nécessite qu'un seul neurone qui produit une valeur continue plutôt que des probabilités. La fonction d'activation utilisée dépend de la plage de valeurs de sortie souhaitée. Par exemple, pour une régression linéaire simple, une activation linéaire peut être utilisée. Si les valeurs de sortie doivent être bornées dans une plage spécifique, des fonctions d'activation comme la fonction sigmoïde ou la fonction tanh peuvent être utilisées.\n",
    "\n",
    "    Il est important de noter que le choix de l'architecture n'est pas uniquement basé sur le type de problème, mais aussi sur la complexité des données, la disponibilité des ressources de calcul et les contraintes temporelles. Dans certains cas, des architectures plus avancées, telles que les réseaux de neurones convolutifs (CNN) pour les problèmes d'imagerie, ou les réseaux de neurones récurrents (RNN) pour les problèmes de séquence, peuvent être plus appropriées. La sélection de l'architecture du PMC peut nécessiter des expérimentations itératives et des ajustements en fonction des performances du modèle sur les données d'entraînement et de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48667dc3-a375-49d6-8b8b-f6a455106abd",
   "metadata": {},
   "source": [
    "### 3. Définissez les termes suivants : Fonction d’activation, Propagation, rétropropagation, Loss-function, Descente de gradient, Vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeda38b-0cf6-4850-a9a2-379c641d0f19",
   "metadata": {},
   "source": [
    "    1. Fonction d'activation : Une fonction d'activation est une fonction mathématique appliquée à la sortie d'un neurone. Elle introduit une non-linéarité dans le modèle et permet au PMC de modéliser des relations complexes entre les variables d'entrée et de sortie. Des exemples courants de fonctions d'activation sont la fonction sigmoïde, la fonction ReLU (Rectified Linear Unit), la fonction tanh (tangente hyperbolique) et la fonction softmax.\n",
    "\n",
    "    2. Propagation : La propagation, également appelée propagation avant (forward propagation), est le processus de calcul de la sortie du PMC à partir des données d'entrée. L'information se propage à travers les différentes couches du réseau, avec chaque neurone calculant une somme pondérée de ses entrées et appliquant ensuite une fonction d'activation à cette somme pour produire sa sortie.\n",
    "\n",
    "    3. Rétropropagation : La rétropropagation, également appelée rétropropagation du gradient (backpropagation), est un algorithme utilisé pour entraîner le PMC en ajustant les poids des neurones. L'idée principale de la rétropropagation est de calculer le gradient de l'erreur par rapport aux poids du réseau en utilisant la règle de dérivation en chaîne. Ce gradient est ensuite utilisé pour mettre à jour les poids du réseau de manière à minimiser l'erreur lors de l'apprentissage.\n",
    "\n",
    "    4. Loss-function : Une loss-function (fonction de perte) est une mesure de l'erreur entre les prédictions du PMC et les valeurs réelles attendues. Elle quantifie la différence entre les sorties du réseau et les vérités terrain. L'objectif de l'apprentissage est de minimiser cette fonction de perte. Des exemples de fonctions de perte couramment utilisées sont l'erreur quadratique moyenne (MSE), l'entropie croisée (cross-entropy) et la log-vraisemblance négative (negative log-likelihood).\n",
    "\n",
    "    5. Descente de gradient : La descente de gradient (gradient descent) est un algorithme d'optimisation utilisé pour ajuster les poids du PMC afin de minimiser la fonction de perte. Il fonctionne en calculant le gradient de la fonction de perte par rapport aux poids et en mettant à jour les poids dans la direction opposée du gradient. Cela permet de converger vers un minimum local (ou global) de la fonction de perte.\n",
    "\n",
    "    6. Vanishing gradients : Les vanishing gradients (gradients qui disparaissent) font référence à un problème qui se produit lors de l'entraînement des réseaux de neurones profonds. Lors de la rétropropagation, les gradients peuvent devenir très petits à mesure qu'ils se propagent des couches supérieures aux couches inférieures du réseau. Cela peut rendre l'apprentissage difficile, car les poids des neurones dans les couches inférieures sont mis à jour de manière insignifiante. Les vanishing gradients peuvent entraîner une convergence lente du modèle ou une stagnation de l'apprentissage. Des techniques comme l'initialisation des poids, l'utilisation de fonctions d'activation appropriées et des architectures spécifiques (comme les réseaux résiduels) sont souvent utilisées pour atténuer ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f229300-2597-41c8-9fb1-9e106829639e",
   "metadata": {},
   "source": [
    "### 4. Qu’est ce qu’une fonction d’activation ? Donnez des exemples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd9154-901b-4b38-84e0-33ad367441ee",
   "metadata": {},
   "source": [
    "Une fonction d'activation est une fonction mathématique appliquée à la sortie d'un neurone dans un réseau de neurones. Elle introduit une non-linéarité dans le modèle, ce qui permet au réseau de modéliser des relations complexes entre les variables d'entrée et de sortie. Les fonctions d'activation sont essentielles dans les réseaux de neurones, car sans elles, le modèle se réduirait à une simple combinaison linéaire des entrées.\n",
    "\n",
    "Voici quelques exemples courants de fonctions d'activation utilisées dans les réseaux de neurones :\n",
    "\n",
    "    1. Fonction sigmoïde (sigmoid) :\n",
    "        La fonction sigmoïde est définie comme f(x) = 1 / (1 + exp(-x)). Elle produit une sortie comprise entre 0 et 1, ce qui permet de l'utiliser pour modéliser des probabilités. Elle était couramment utilisée dans les réseaux de neurones plus anciens, mais son utilisation a diminué en faveur d'autres fonctions d'activation en raison de certains inconvénients, notamment la disparition des gradients (vanishing gradients).\n",
    "\n",
    "    2. Fonction ReLU (Rectified Linear Unit) :\n",
    "        La fonction ReLU est définie comme f(x) = max(0, x). Elle renvoie simplement la valeur d'entrée si elle est positive, sinon elle renvoie zéro. La fonction ReLU est non linéaire et présente l'avantage de ne pas souffrir de vanishing gradients, ce qui la rend populaire dans de nombreux réseaux de neurones profonds.\n",
    "\n",
    "    3. Fonction tanh (tangente hyperbolique) :\n",
    "        La fonction tanh est définie comme f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x)). Elle produit une sortie comprise entre -1 et 1, ce qui la rend similaire à la fonction sigmoïde. Cependant, la fonction tanh est centrée sur zéro, ce qui signifie qu'elle peut être plus appropriée pour les tâches de classification qui nécessitent des valeurs positives et négatives.\n",
    "\n",
    "    4. Fonction softmax :\n",
    "        La fonction softmax est souvent utilisée dans la couche de sortie des réseaux de neurones pour des problèmes de classification multiclasse. Elle prend un vecteur de valeurs réelles en entrée et produit un vecteur de probabilités normalisées qui représentent la distribution de probabilité sur les classes. La fonction softmax est définie comme f(x) = exp(x) / sum(exp(x)).\n",
    "\n",
    "Ces exemples ne représentent qu'une petite sélection de fonctions d'activation utilisées dans les réseaux de neurones. Il existe d'autres fonctions d'activation, telles que la fonction Leaky ReLU, la fonction ELU (Exponential Linear Unit), la fonction PReLU (Parametric Rectified Linear Unit), etc. Le choix de la fonction d'activation dépend souvent du problème spécifique, de l'architecture du réseau et des performances empiriques observées lors de l'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426510f-1958-49c1-8aea-c0bb1cd4496b",
   "metadata": {},
   "source": [
    "### 5. Définissez et différenciez les notions d’Epochs, d’Iterations et de Batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153805db-a851-4137-bb08-cbb7e3d200e5",
   "metadata": {},
   "source": [
    "Les notions d'epochs, d'iterations et de batch size sont toutes liées à l'entraînement d'un modèle d'apprentissage automatique, y compris les réseaux de neurones. Elles sont utilisées pour contrôler la façon dont les données d'entraînement sont utilisées lors du processus d'apprentissage.\n",
    "\n",
    "    1. Epochs (Époques) :\n",
    "        Un epoch représente une passe complète de l'ensemble des données d'entraînement lors de l'apprentissage d'un modèle. Pendant une epoch, le modèle traite et apprend des informations de chaque exemple d'entraînement une fois. Une epoch se termine lorsque tous les exemples d'entraînement ont été utilisés pour mettre à jour les poids du modèle. L'utilisation de plusieurs epochs permet au modèle de voir les données d'entraînement à plusieurs reprises, améliorant ainsi la capacité d'apprentissage.\n",
    "\n",
    "    2. Iterations (Itérations) :\n",
    "        Une itération fait référence à une étape d'entraînement où un certain nombre d'exemples d'entraînement, appelé batch size, sont utilisés pour mettre à jour les poids du modèle. En d'autres termes, une itération consiste à propager un batch d'exemples d'entraînement à travers le modèle, calculer la perte (loss), rétropropager les gradients et mettre à jour les poids du modèle. Le nombre d'itérations nécessaire pour terminer une epoch dépend de la taille des données d'entraînement et du batch size utilisé.\n",
    "\n",
    "    3. Batch size (Taille de lot) :\n",
    "        Le batch size est le nombre d'exemples d'entraînement utilisés dans une seule itération d'entraînement. Il détermine la quantité de données sur laquelle les poids du modèle sont mis à jour à chaque itération. Un batch size plus grand signifie que plus d'exemples d'entraînement sont utilisés ensemble, ce qui peut accélérer le temps d'entraînement, mais cela nécessite également plus de mémoire. Un batch size plus petit peut ralentir l'entraînement, mais peut permettre une meilleure généralisation du modèle et une exploration plus fine du paysage des gradients.\n",
    "\n",
    "Pour résumer, lors de l'entraînement d'un modèle :\n",
    "- Une epoch correspond à une passe complète à travers toutes les données d'entraînement.\n",
    "- Une itération représente une étape d'entraînement où un batch size d'exemples est utilisé pour mettre à jour les poids du modèle.\n",
    "- Le batch size détermine le nombre d'exemples utilisés pour chaque itération.\n",
    "\n",
    "Ces concepts sont souvent utilisés ensemble pour organiser le processus d'entraînement, en déterminant combien de fois les données d'entraînement doivent être vues (epochs), combien d'itérations sont nécessaires pour terminer une epoch et combien d'exemples sont utilisés à chaque itération (batch size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3d483-072a-4625-ab4c-4a7e23512dae",
   "metadata": {},
   "source": [
    "### 6. Qu’est ce que l’hyper-paramètre learning rate ? Quelles sont les conséquences d’un learning rate trop bas ou trop élevé ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a7f50-f6af-47d4-b146-5dcd29085439",
   "metadata": {},
   "source": [
    "Le learning rate, ou taux d'apprentissage, est un hyperparamètre utilisé dans les algorithmes d'optimisation, tels que la descente de gradient, pour contrôler la taille des pas de mise à jour des poids lors de l'apprentissage d'un modèle.\n",
    "\n",
    "    Un learning rate trop bas (underfitting) :\n",
    "    Si le learning rate est trop bas, le processus d'apprentissage peut être très lent, car les mises à jour des poids sont effectuées avec de très petits pas. Cela peut prolonger le temps d'entraînement du modèle, nécessitant potentiellement un plus grand nombre d'epochs pour atteindre une convergence satisfaisante. De plus, un learning rate trop bas peut également entraîner un risque de convergence vers un minimum local suboptimal, car les mises à jour des poids sont très lentes et peuvent rester piégées dans des régions de l'espace de recherche sous-optimales.\n",
    "\n",
    "    Un learning rate trop élevé (overfitting) :\n",
    "    Si le learning rate est trop élevé, le processus d'apprentissage peut être instable et les poids peuvent osciller de manière erratique. Cela peut conduire à une convergence lente, voire à l'absence de convergence, car les mises à jour des poids sont trop grandes et peuvent ne pas se rapprocher du minimum global. De plus, un learning rate trop élevé peut également provoquer des dépassements (overflow) ou des oscillations autour du minimum, ce qui entraîne une performance médiocre sur les données de validation et de test. Un learning rate excessivement élevé peut même causer la divergence du modèle.\n",
    "\n",
    "Il est important de sélectionner un learning rate approprié pour chaque problème spécifique. Une approche courante consiste à effectuer une recherche par grille ou une recherche aléatoire pour tester différents learning rates et évaluer les performances du modèle sur un ensemble de validation. Des méthodes d'optimisation avancées, telles que la décroissance adaptative du learning rate (adaptive learning rate decay) ou l'utilisation d'algorithmes d'optimisation tels que l'Adam optimizer, peuvent également être utilisées pour ajuster automatiquement le learning rate au cours de l'entraînement afin d'optimiser les performances du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6391094-67a1-4f63-b923-710204bf12f4",
   "metadata": {},
   "source": [
    "### 7. Définissez la Batch normalization et argumentez son utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a30a990-c0a4-4e6c-94e5-d738553c0689",
   "metadata": {},
   "source": [
    "La Batch Normalization (normalisation par lot) est une technique utilisée dans les réseaux de neurones pour normaliser les activations des neurones en ajustant et en normalisant les valeurs de chaque mini-lot de données pendant l'entraînement. Elle a été proposée pour améliorer la stabilité et la vitesse de convergence des réseaux de neurones profonds.\n",
    "\n",
    "L'idée principale derrière la Batch Normalization est de réduire le problème du décalage des distributions d'activation dans les couches cachées d'un réseau de neurones. Lors de l'entraînement d'un réseau de neurones, les activations des neurones dans les différentes couches peuvent varier considérablement, car les poids sont mis à jour à chaque itération. Cela peut ralentir la convergence du modèle et rendre l'apprentissage plus difficile.\n",
    "\n",
    "La Batch Normalization résout ce problème en normalisant les activations de chaque mini-lot d'exemples d'entraînement, en les centrant autour de zéro et en les mettant à l'échelle avec une variance unitaire. Cela se fait en utilisant les moyennes et les variances calculées pour chaque mini-lot, puis en appliquant une transformation linéaire pour centrer et mettre à l'échelle les activations. Cette normalisation se fait au niveau de chaque couche, entre les couches cachées et les fonctions d'activation.\n",
    "\n",
    "L'utilisation de la Batch Normalization présente plusieurs avantages :\n",
    "\n",
    "        1. Réduction du décalage de distribution : La Batch Normalization réduit le décalage de distribution en normalisant les activations. Cela permet aux couches suivantes du réseau de commencer l'apprentissage à partir d'un état plus stable, favorisant ainsi la convergence plus rapide du modèle.\n",
    "\n",
    "        2. Régularisation : La Batch Normalization agit comme une forme de régularisation en ajoutant un peu de bruit à chaque mini-lot. Cela peut réduire l'overfitting et améliorer la généralisation du modèle.\n",
    "\n",
    "        3. Réduction de la sensibilité aux paramètres d'initialisation : La Batch Normalization réduit la dépendance des performances du modèle à des paramètres d'initialisation spécifiques. Cela permet d'utiliser des taux d'apprentissage plus élevés sans risquer la divergence.\n",
    "\n",
    "        4. Stabilité numérique : La Batch Normalization peut améliorer la stabilité numérique du modèle en réduisant les valeurs des activations, ce qui peut aider à prévenir les problèmes tels que les explosions ou les disparitions des gradients.\n",
    "\n",
    "En résumé, la Batch Normalization est une technique populaire dans l'entraînement des réseaux de neurones profonds. Elle améliore la stabilité, la vitesse de convergence et la généralisation du modèle en normalisant les activations à chaque mini-lot. Cependant, il convient de noter que l'utilisation de la Batch Normalization peut introduire un coût de calcul supplémentaire et peut ne pas toujours être nécessaire dans des architectures plus récentes, telles que les réseaux résiduels ou les réseaux avec des fonctions d'activation non saturantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b3c35-518f-4743-81f8-184f3b4c63bc",
   "metadata": {},
   "source": [
    "### 8. Qu'est-ce que l'algorithme d'optimisation d'Adam ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afc1d4-33da-48bc-8b4d-aa50629ac779",
   "metadata": {},
   "source": [
    "L'algorithme d'optimisation Adam (Adaptive Moment Estimation) est un algorithme d'optimisation populaire utilisé pour entraîner des modèles de réseaux de neurones. Il est particulièrement efficace dans les problèmes d'apprentissage en profondeur où les données peuvent être très complexes et non linéaires.\n",
    "\n",
    "L'algorithme Adam combine les avantages de deux autres algorithmes d'optimisation : la descente de gradient stochastique (SGD) avec moment et l'adapteur de taux d'apprentissage (Adagrad).\n",
    "\n",
    "Voici les principes clés de l'algorithme Adam :\n",
    "\n",
    "1. Moments du premier ordre et du second ordre :\n",
    "Adam maintient deux moments pour chaque poids du modèle : le moment du premier ordre (la moyenne des gradients) et le moment du second ordre (la moyenne des carrés des gradients).\n",
    "\n",
    "2. Adaptation du taux d'apprentissage :\n",
    "Adam ajuste automatiquement le taux d'apprentissage pour chaque poids du modèle en utilisant les moments du premier ordre et du second ordre. Il admet une forme de taux d'apprentissage adaptatif qui réduit les fluctuations du taux d'apprentissage au cours de l'entraînement.\n",
    "\n",
    "3. Biais corrigé :\n",
    "Puisque les moments du premier et du second ordre sont initialisés à zéro, il existe un biais vers zéro au début de l'entraînement. Adam corrige ce biais en utilisant un facteur de correction biaisé pour les moments.\n",
    "\n",
    "L'algorithme Adam combine ces principes pour effectuer les mises à jour des poids du modèle. Les étapes générales de l'algorithme sont les suivantes :\n",
    "\n",
    "1. Initialiser les moments du premier et du second ordre à zéro.\n",
    "2. À chaque itération, calculer les gradients pour un mini-lot d'exemples d'entraînement.\n",
    "3. Mettre à jour les moments du premier et du second ordre en utilisant les gradients.\n",
    "4. Corriger les biais des moments.\n",
    "5. Mettre à jour les poids du modèle en utilisant les moments corrigés et le taux d'apprentissage adapté.\n",
    "\n",
    "L'algorithme Adam offre plusieurs avantages par rapport à d'autres méthodes d'optimisation. Il est adaptatif, ce qui signifie qu'il peut ajuster automatiquement le taux d'apprentissage en fonction des caractéristiques de l'ensemble de données. Il est également efficace pour les problèmes avec des gradients clairsemés ou bruités. Enfin, Adam est largement utilisé dans la pratique et a montré de bonnes performances sur une variété de tâches d'apprentissage en profondeur.\n",
    "\n",
    "Il convient de noter que le choix de l'algorithme d'optimisation dépend du problème spécifique et des caractéristiques des données. Différentes variantes de l'algorithme Adam existent également, telles que AdamW et AMSGrad, qui introduisent des ajustements supplémentaires pour améliorer les performances sur certaines tâches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251bed6-7fee-47c5-90fa-52a8ecdb4b0c",
   "metadata": {},
   "source": [
    "### 9. Définissez simplement ce qu’est un Perceptron multicouches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e5028-9bc9-4788-b4b8-65dcfa7f5cd9",
   "metadata": {},
   "source": [
    "Un Perceptron multicouches est un type de modèle d'apprentissage automatique, également connu sous le nom de réseau de neurones multicouches. Il est composé de plusieurs couches de neurones artificiels organisées de manière hiérarchique.\n",
    "\n",
    "Chaque neurone dans un Perceptron multicouches est connecté à tous les neurones de la couche précédente et de la couche suivante. Les couches d'entrée reçoivent les données d'entrée et les transmettent aux couches cachées, qui effectuent des calculs et des transformations pour extraire des caractéristiques des données. Enfin, les couches de sortie produisent les résultats finaux du modèle.\n",
    "\n",
    "Chaque neurone dans un Perceptron multicouches effectue une combinaison linéaire des entrées pondérées par des poids, puis applique une fonction d'activation non linéaire à cette somme pour générer une sortie. Les fonctions d'activation introduisent de la non-linéarité dans le modèle, lui permettant de modéliser des relations complexes entre les variables d'entrée et de sortie.\n",
    "\n",
    "L'objectif de l'apprentissage d'un Perceptron multicouches est d'ajuster les poids de manière à minimiser une fonction de perte, qui mesure l'écart entre les prédictions du modèle et les valeurs réelles attendues. Cela se fait généralement en utilisant des techniques d'optimisation telles que la descente de gradient et la rétropropagation du gradient, qui ajustent les poids du modèle en se basant sur les erreurs calculées lors de la propagation avant et arrière des données.\n",
    "\n",
    "En résumé, un Perceptron multicouches est un modèle d'apprentissage automatique qui utilise des couches de neurones artificiels, des fonctions d'activation non linéaires et des techniques d'optimisation pour apprendre à partir des données et effectuer des prédictions sur de nouvelles entrées. Il est utilisé dans une variété de domaines, tels que la classification, la régression, la reconnaissance de formes et le traitement du langage naturel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
